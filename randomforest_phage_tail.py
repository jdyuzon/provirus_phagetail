# -*- coding: utf-8 -*-
"""RandomForest_phage_trail.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/187zVEskinEf0nK5ctWd2CN1RsgY594iy
"""

####################### Random Forest scripts adapted from:
#### https://towardsdatascience.com/machine-learning-step-by-step-6fbde95c455a

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2

import pandas as pd
import os

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
norm_e = StandardScaler()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import recall_score
from sklearn.inspection import permutation_importance
from sklearn.metrics import classification_report

### set work directory
os.chdir("/pscratch/sd/j/jdyuzon/snakemake-bacteriophage2")

genes_phage_tail_variables=pd.read_csv("prediction_out/genes_phage_tail_variables.csv")
y=genes_phage_tail_variables['type']
y=y.replace('Phage1',1)
y=y.replace('Phage2',1)
y=y.replace('T6SS',0)
y=y.replace('eCIS',0)
X=genes_phage_tail_variables.drop(['viral_ID','type'], axis =1, inplace=False)
genes_phage_tail_variables=genes_phage_tail_variables.drop(columns=['Unnamed: 0'])
X=X.drop(columns=['Unnamed: 0'])
X

### Perform the train-test split
X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.25, stratify=y)
print(X_train.shape)
### No need to transform binary variables
### Write tables
X_train.to_csv('prediction_out/random_forest/X_train.csv')
X_test.to_csv('prediction_out/random_forest/X_test.csv')
y_train.to_csv('prediction_out/random_forest/y_train.csv')
y_test.to_csv('prediction_out/random_forest/y_test.csv')

### Are there overlaps in test and train datasets? train_test_split should sample without replacement so no overlaps
pd.merge(X_train, X_test, how='inner')

### Load data
#X_train = pd.read_csv('prediction_out/random_forest/X_train.csv')
#X_test = pd.read_csv('prediction_out/random_forest/X_test.csv')
#y_train = pd.read_csv('prediction_out/random_forest/y_train.csv')
#y_test = pd.read_csv('prediction_out/random_forest/y_test.csv')

X_train

y_train

###instantiate the model and fit the scaled data to it
rfc = RandomForestClassifier(n_estimators=1000)
rfc.fit(X_train, y_train)
# Test score (accuracy) for training data
rfc.score(X_train, y_train)

# Test score (accuracy) for test data
rfc.score(X_test, y_test)

# View the classification report for test data and predictions
y_pred_test = rfc.predict(X_test)
print(classification_report(y_test, y_pred_test))

importances = rfc.feature_importances_
features=X_train

### Feature importance based on GINI/Mean Decrease in Impurity (MDI)
feats = {}
for feature, importance in zip(X_train, rfc.feature_importances_):
    feats[feature] = importance

importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})
importances = importances.sort_values(by='Gini-Importance', ascending=False)
importances = importances.reset_index()
importances = importances.rename(columns={'index': 'Features'})
importances[0:10]

importances.to_csv('prediction_out/random_forest/GINI_importances.csv', sep='\t')